{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.amazon.pl/s?k=ekspres+ci%C5%9Bnieniowy&__mk_pl_PL=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=249AWWJCXNNBX&sprefix=ekspres+ci%C5%9Bnieniowy%2Caps%2C85&ref=nb_sb_noss_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for request\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.42'\n",
    "\n",
    "HEADERS = ({'User-Agent':user_agent, 'Accept-Language': 'pl-PL, pl; q=0.5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTTP Request\n",
    "webpage = requests.get(URL, headers = HEADERS)\n",
    "\n",
    "#<Response [200]> == Success\n",
    "webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(webpage.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup object containing all data\n",
    "soup = BeautifulSoup(webpage.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch links as list of tag objects\n",
    "links = soup.find_all(\"a\", attrs={'class': 'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "max_site = int(soup.find(\"span\", attrs={\"class\": \"s-pagination-item s-pagination-disabled\"}).text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_list = []\n",
    "\n",
    "for link in links:\n",
    "    adress = link.get('href')\n",
    "    links_list.append(adress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(x):\n",
    "    try:\n",
    "        title = x.find(\"span\", attrs={\"id\": \"productTitle\"}).text.strip()\n",
    "        return title\n",
    "\n",
    "    except AttributeError:\n",
    "        return \"\"\n",
    "\n",
    "def get_brand(x):\n",
    "    try:\n",
    "        brand = x.find(\"td\", attrs={\"class\": \"a-span9\"}).text.strip()\n",
    "        return brand\n",
    "\n",
    "    except AttributeError:\n",
    "        return \"\"\n",
    "\n",
    "def get_price(x):\n",
    "    try:\n",
    "        price = x.find(\"span\", attrs={\"class\": \"a-offscreen\"}).text.strip().replace(\"zł\",\"\").replace(',','.')\n",
    "        return price\n",
    "\n",
    "    except AttributeError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'title': [],\"brand\":[], \"price\": []}\n",
    "\n",
    "for link in links_list:\n",
    "    # HTTP Requests\n",
    "    product_link = \"https://amazon.pl\" + link\n",
    "    new_webpage = requests.get(product_link, headers = HEADERS)\n",
    "    \n",
    "    # soup object containing all data\n",
    "    new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "\n",
    "    \n",
    "    data['title'].append(get_title(new_soup))\n",
    "    data['brand'].append(get_brand(new_soup))\n",
    "    data['price'].append(get_price(new_soup))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.pl/s?k=ekspres+ci%C5%9Bnieniowy&page=2&__mk_pl_PL=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=249AWWJCXNNBX&qid=1668784032&sprefix=ekspres+ci%C5%9Bnieniowy%2Caps%2C85&ref=sr_pg_1\n",
      "https://www.amazon.pl/s?k=ekspres+ci%C5%9Bnieniowy&page=3&__mk_pl_PL=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=249AWWJCXNNBX&qid=1668784032&sprefix=ekspres+ci%C5%9Bnieniowy%2Caps%2C85&ref=sr_pg_2\n",
      "https://www.amazon.pl/s?k=ekspres+ci%C5%9Bnieniowy&page=4&__mk_pl_PL=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=249AWWJCXNNBX&qid=1668784032&sprefix=ekspres+ci%C5%9Bnieniowy%2Caps%2C85&ref=sr_pg_3\n",
      "https://www.amazon.pl/s?k=ekspres+ci%C5%9Bnieniowy&page=5&__mk_pl_PL=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=249AWWJCXNNBX&qid=1668784032&sprefix=ekspres+ci%C5%9Bnieniowy%2Caps%2C85&ref=sr_pg_4\n",
      "https://www.amazon.pl/s?k=ekspres+ci%C5%9Bnieniowy&page=6&__mk_pl_PL=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=249AWWJCXNNBX&qid=1668784032&sprefix=ekspres+ci%C5%9Bnieniowy%2Caps%2C85&ref=sr_pg_5\n",
      "https://www.amazon.pl/s?k=ekspres+ci%C5%9Bnieniowy&page=7&__mk_pl_PL=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=249AWWJCXNNBX&qid=1668784032&sprefix=ekspres+ci%C5%9Bnieniowy%2Caps%2C85&ref=sr_pg_6\n"
     ]
    }
   ],
   "source": [
    "# Pages 2 - MAX\n",
    "\n",
    "start = 2\n",
    "stop = max_site + 1\n",
    "progress = start\n",
    "while progress < stop:\n",
    "    URL = \"https://www.amazon.pl/s?k=ekspres+ci%C5%9Bnieniowy&page={}&__mk_pl_PL=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=249AWWJCXNNBX&qid=1668784032&sprefix=ekspres+ci%C5%9Bnieniowy%2Caps%2C85&ref=sr_pg_{}\".format(progress, progress - 1)\n",
    "    print(URL)\n",
    "    progress += 1\n",
    "\n",
    "    # HTTP Request\n",
    "    webpage = requests.get(URL, headers = HEADERS)\n",
    "\n",
    "    # soup object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "\n",
    "    # Fetch links as list of tag objects\n",
    "    links = soup.find_all(\"a\", attrs={'class': 'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "\n",
    "    links_list = []\n",
    "\n",
    "    for link in links:\n",
    "        adress = link.get('href')\n",
    "        links_list.append(adress)\n",
    "\n",
    "    for link in links_list:\n",
    "        # HTTP Requests\n",
    "        product_link = \"https://amazon.pl\" + link\n",
    "        new_webpage = requests.get(product_link, headers = HEADERS)\n",
    "        \n",
    "        # soup object containing all data\n",
    "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "\n",
    "        \n",
    "        data['title'].append(get_title(new_soup))\n",
    "        data['brand'].append(get_brand(new_soup))\n",
    "        data['price'].append(get_price(new_soup))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df = pd.DataFrame.from_dict(data)\n",
    "amazon_df['title'].replace('', np.nan, inplace=True)\n",
    "amazon_df = amazon_df.dropna(subset=['title'])\n",
    "amazon_df.to_csv('amazon_data.csv', header=True, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russell Hobbs ekspres do kawy, ciśnieniowy, 15...</td>\n",
       "      <td>Russell Hobbs</td>\n",
       "      <td>1 179.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russell Hobbs ekspres do kawy, ciśnieniowy, 15...</td>\n",
       "      <td>Russell Hobbs</td>\n",
       "      <td>999.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saeco 229452100 oryginalny zawór ciśnieniowy z...</td>\n",
       "      <td></td>\n",
       "      <td>86.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ufesa CE 7238 Cream - Ekspres do kawy, do przy...</td>\n",
       "      <td>UFESA</td>\n",
       "      <td>499.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>De'Longhi Stilosa Advanced EC235.BK ekspres do...</td>\n",
       "      <td>De'Longhi</td>\n",
       "      <td>405.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          brand     price\n",
       "0  Russell Hobbs ekspres do kawy, ciśnieniowy, 15...  Russell Hobbs  1 179.00\n",
       "1  Russell Hobbs ekspres do kawy, ciśnieniowy, 15...  Russell Hobbs    999.99\n",
       "2  Saeco 229452100 oryginalny zawór ciśnieniowy z...                    86.39\n",
       "3  Ufesa CE 7238 Cream - Ekspres do kawy, do przy...          UFESA    499.00\n",
       "4  De'Longhi Stilosa Advanced EC235.BK ekspres do...      De'Longhi    405.69"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
